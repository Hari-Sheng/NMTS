{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attention\n",
    "## 0. Project structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `main.py`: parses the config input and run basic tests\n",
    "- `data.py`: provides the data iterator and data processing\n",
    "- `test_iterator.py`: tests the data iterator\n",
    "- `data\\`: training data\n",
    "- `checkpoints\\`: checkpoints of model parameters\n",
    "- `logs\\`: logs of loss, accuracy, etc.\n",
    "- `model.py`: \n",
    "    - `build_variables()`: prepares the variable placeholder\n",
    "    - `build_model()`: prepares the model\n",
    "    - `train()`: train the model\n",
    "    - `test()`: calculate test error\n",
    "    - `countParameters()`: count the parameters in the model\n",
    "    - `load()`: load the model from checkpoints\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Model architecture and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_size       = 30\n",
    "batch_size     = 64\n",
    "max_epochs     = 10\n",
    "embedding_size = 128\n",
    "hidden_size    = 512\n",
    "LSTM_layer     = 4\n",
    "drop_out       = 0.2\n",
    "init_range     = [-0.1, 0.1]\n",
    "learning_rate  = 1  # anneal every epoch after 5\n",
    "max_grad_norm  = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Improvements\n",
    "- Seperate the model, main controller and data iterator (MEM)\n",
    "- Using CPU version of tensorflow for half a week: manually attaching the device but I should let tf do that\n",
    "    - training overnight and only finished one epoch\n",
    "    - tf default GPU version is 9x speed up\n",
    "- Always debug using a simple architecture first, cause the init takes miniutes at least."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Training experiments\n",
    "### 3.1. en-vi small dataset\n",
    "\n",
    "Trained for 11 hours, 24k steps roughtly 10 epochs, although the loss seems to keep dropping. \n",
    "\n",
    "- vocab: 17k -> 7k\n",
    "- speed: 64 pairs of sentences per 1.5s -> 153k per hour\n",
    "- trian_error = 3-3.3\n",
    "- test_error = 3.05\n",
    "- test_perplexity = 26\n",
    "![](attention_small.png)\n",
    "![](attention_small_summary.png)\n",
    "### 3.2. en-de medium dataset\n",
    "Trained for 3 hours\n",
    "\n",
    "- vocab: 5k -> 5k\n",
    "- speed: 128k pairs of sentences per 3s -> 153k per hour\n",
    "- trian_error = 5-5.5\n",
    "- test_error = 5.5\n",
    "- test_perplexity = 270"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## n. Todo list\n",
    "- [add validation error summarizer](http://stackoverflow.com/questions/35387109/validation-and-test-with-tensorflow)\n",
    "- preprocess the data\n",
    "    - shuffle\n",
    "    - sort by length\n",
    "- dynamic LSTM?\n",
    "- pretraining the wordvector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
